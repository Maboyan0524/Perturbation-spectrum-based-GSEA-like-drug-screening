import pandas as pd
import numpy as np
from scipy.stats import rankdata, norm
import warnings
from tqdm import tqdm
import multiprocessing as mp
from functools import partial
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.collections import LineCollection
from matplotlib.colors import LinearSegmentedColormap

# å¿½ç•¥å­—ä½“è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')
warnings.filterwarnings('ignore', category=UserWarning, module='tkinter')

# è®¾ç½®å­—ä½“å’Œæ ·å¼
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['Times New Roman']
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']  # ä¿ç•™ sans-serif ä»¥æ”¯æŒä¸­æ–‡ fallback
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("white")
plt.rcParams['figure.dpi'] = 100


# === 1. è¯»å–æ‰°åŠ¨è°±æ•°æ®ï¼šlong format è½¬ wide formatï¼Œå¹¶åº”ç”¨å®½æ ¼å¼å¤„ç†é€»è¾‘ ===
def load_expression_matrix_from_long_table(file_path):
    try:
        df = pd.read_csv(file_path)
        df = df[["gene_id", "Treat_Sample", "LogFC"]].dropna()

        # å¤„ç†é‡å¤ï¼ˆå–å¹³å‡ï¼‰
        duplicates = df.duplicated(subset=["gene_id", "Treat_Sample"], keep=False)
        if duplicates.any():
            print("âš ï¸ æ£€æµ‹åˆ°é‡å¤ gene_id-Treat_Sample ç»„åˆï¼Œè‡ªåŠ¨å¯¹è¿™äº›å€¼å–å¹³å‡")
            df = df.groupby(["gene_id", "Treat_Sample"], as_index=False).mean()

        # Pivot to wide
        matrix = df.pivot(index="gene_id", columns="Treat_Sample", values="LogFC")
        matrix.columns.name = None

        # åº”ç”¨å®½æ ¼å¼é¢å¤–å¤„ç†ï¼ˆç»Ÿä¸€å¤§å†™ç´¢å¼•ï¼Œç¡®ä¿æ•°å€¼ï¼Œå»é™¤å…¨NaNåˆ—ï¼‰
        matrix.index = matrix.index.astype(str).str.upper()
        matrix = matrix.apply(pd.to_numeric, errors='coerce')
        matrix = matrix.dropna(axis=1, how='all')

        # é¢å¤–ï¼šæ›¿æ¢ä»»ä½•infå€¼ä¸ºNaNï¼ˆé˜²æ­¢ä¸‹æ¸¸è®¡ç®—é—®é¢˜ï¼‰
        matrix = matrix.replace([np.inf, -np.inf], np.nan)

        print(f"âœ… åŠ è½½è¡¨è¾¾çŸ©é˜µ: {matrix.shape[0]} åŸºå›  Ã— {matrix.shape[1]} è¯ç‰©")
        return matrix

    except Exception as e:
        print(f"âŒ è¯»å–è¡¨è¾¾æ•°æ®å¤±è´¥: {e}")
        return None


# === 2. è¯»å–ä¸Šä¸‹è°ƒåŸºå› é›†ï¼ˆæ·»åŠ æ£€æŸ¥é€»è¾‘ï¼‰ ===
def load_gene_set_from_symbol_files(up_path, down_path):
    try:
        up_genes = set(pd.read_csv(up_path)["gene_id"].astype(str).str.upper().dropna().tolist())
        down_genes = set(pd.read_csv(down_path)["gene_id"].astype(str).str.upper().dropna().tolist())

        print(f"âœ… ä¸Šè°ƒåŸºå› é›†: {len(up_genes)} ä¸ªåŸºå› ")
        print(f"âœ… ä¸‹è°ƒåŸºå› é›†: {len(down_genes)} ä¸ªåŸºå› ")

        # æ£€æŸ¥åŸºå› é›†å¤§å°
        if len(up_genes) < 5:
            warnings.warn(f"âš ï¸ ä¸Šè°ƒåŸºå› é›†å¤ªå°({len(up_genes)}ä¸ª)ï¼Œå¯èƒ½å½±å“GSEAæ•ˆåŠ›")
        if len(down_genes) < 5:
            warnings.warn(f"âš ï¸ ä¸‹è°ƒåŸºå› é›†å¤ªå°({len(down_genes)}ä¸ª)ï¼Œå¯èƒ½å½±å“GSEAæ•ˆåŠ›")
        if len(up_genes) > 500:
            warnings.warn(f"âš ï¸ ä¸Šè°ƒåŸºå› é›†å¾ˆå¤§({len(up_genes)}ä¸ª)ï¼ŒGSEAå¯èƒ½ä¸å¤Ÿæ•æ„Ÿ")
        if len(down_genes) > 500:
            warnings.warn(f"âš ï¸ ä¸‹è°ƒåŸºå› é›†å¾ˆå¤§({len(down_genes)}ä¸ª)ï¼ŒGSEAå¯èƒ½ä¸å¤Ÿæ•æ„Ÿ")

        # æ£€æŸ¥é‡å 
        overlap = up_genes & down_genes
        if overlap:
            warnings.warn(f"âš ï¸ ä¸Šä¸‹è°ƒåŸºå› é›†æœ‰ {len(overlap)} ä¸ªé‡å åŸºå› ï¼Œå°†ä»ä¸‹è°ƒé›†ä¸­ç§»é™¤")
            down_genes -= overlap
            print(f"âœ… ä¿®æ­£åä¸‹è°ƒåŸºå› é›†: {len(down_genes)} ä¸ªåŸºå› ")

        return list(up_genes), list(down_genes)

    except Exception as e:
        print(f"âŒ è¯»å–åŸºå› é›†å¤±è´¥: {e}")
        return [], []


# === 3. éªŒè¯åŸºå› é‡å æƒ…å†µ ===
def validate_gene_overlap(expr_matrix, up_genes, down_genes):
    expr_genes = set(expr_matrix.index)
    up_overlap = set(up_genes) & expr_genes
    down_overlap = set(down_genes) & expr_genes

    print(f"ğŸ“Š åŸºå› é‡å ç»Ÿè®¡:")
    print(f"   ä¸Šè°ƒåŸºå› åœ¨è¡¨è¾¾çŸ©é˜µä¸­: {len(up_overlap)}/{len(up_genes)} ({len(up_overlap) / len(up_genes) * 100:.1f}%)")
    print(
        f"   ä¸‹è°ƒåŸºå› åœ¨è¡¨è¾¾çŸ©é˜µä¸­: {len(down_overlap)}/{len(down_genes)} ({len(down_overlap) / len(down_genes) * 100:.1f}%)")

    if len(up_overlap) == 0:
        raise ValueError("âŒ ä¸Šè°ƒåŸºå› é›†ä¸è¡¨è¾¾çŸ©é˜µæ— é‡å !")
    if len(down_overlap) == 0:
        raise ValueError("âŒ ä¸‹è°ƒåŸºå› é›†ä¸è¡¨è¾¾çŸ©é˜µæ— é‡å !")

    # æ£€æŸ¥é‡å æ¯”ä¾‹
    if len(up_overlap) / len(up_genes) < 0.5:
        warnings.warn(f"âš ï¸ ä¸Šè°ƒåŸºå› é›†é‡å ç‡è¾ƒä½({len(up_overlap) / len(up_genes) * 100:.1f}%)ï¼Œå¯èƒ½å½±å“ç»“æœå¯é æ€§")
    if len(down_overlap) / len(down_genes) < 0.5:
        warnings.warn(f"âš ï¸ ä¸‹è°ƒåŸºå› é›†é‡å ç‡è¾ƒä½({len(down_overlap) / len(down_genes) * 100:.1f}%)ï¼Œå¯èƒ½å½±å“ç»“æœå¯é æ€§")

    return up_overlap, down_overlap


# === 4. å•æ¬¡GSEAåˆ†æ•°è®¡ç®—ï¼ˆä½¿ç”¨å®é™…è¡¨è¾¾å€¼æƒé‡ï¼‰ ===
def compute_gsea_score_single(gene_expr_pairs, gene_set, weighted_score_type=1):
    N = len(gene_expr_pairs)
    if N == 0:
        return 0.0

    genes = [gene for gene, _ in gene_expr_pairs]
    expr_values = np.array([expr for _, expr in gene_expr_pairs])

    hits = np.array([gene in gene_set for gene in genes])
    Nh = hits.sum()

    if Nh == 0:
        return 0.0

    no_hits = ~hits

    if weighted_score_type == 0:
        Phit = np.cumsum(hits) / Nh
    else:
        weights = np.abs(expr_values)
        hit_weights = weights[hits]
        if hit_weights.sum() == 0:
            return 0.0
        Phit = np.cumsum(hits * weights) / hit_weights.sum()

    Pmiss = np.cumsum(no_hits) / (N - Nh)

    running_score = Phit - Pmiss
    es_pos = np.max(running_score)
    es_neg = -np.min(running_score)

    return es_pos if es_pos > es_neg else -es_neg


# === 5. å¹¶è¡Œå¤„ç†å•ä¸ªè¯ç‰©çš„åˆ†æï¼ˆä»…è®¡ç®—ESï¼Œæ— på€¼ï¼‰ ===
def analyze_single_drug(args):
    drug, expr_data, up_overlap, down_overlap = args

    expr = expr_data.dropna()
    if len(expr) == 0:
        # å¦‚æœæ— æœ‰æ•ˆåŸºå› ï¼Œè¿”å›NaNä»¥ä¾¿åç»­è¿‡æ»¤
        return {
            "drug_id": drug,
            "es_up": np.nan,
            "es_down": np.nan,
            "wtcs": np.nan,
            "target_scores": {}
        }

    gene_expr_pairs = [(gene, val) for gene, val in expr.sort_values(ascending=False).items()]

    es_up = compute_gsea_score_single(gene_expr_pairs, up_overlap)
    es_down = compute_gsea_score_single(gene_expr_pairs, down_overlap)

    wtcs = (es_up - es_down) / 2

    target_scores = {}
    all_genes = list(up_overlap) + list(down_overlap)
    for gene in all_genes:
        target_scores[gene] = expr.get(gene, np.nan)

    return {
        "drug_id": drug,
        "es_up": es_up,
        "es_down": es_down,
        "wtcs": wtcs,
        "target_scores": target_scores
    }


# === 6. ä¸»å‡½æ•°ï¼šæ‰§è¡ŒGSEA + WTCS + Tauåˆ†æï¼ˆå–æ¶ˆç»Ÿè®¡æ£€éªŒï¼‰ ===
def run_custom_wtcs(expr_matrix, up_genes, down_genes, n_processes=None):
    up_overlap, down_overlap = validate_gene_overlap(expr_matrix, up_genes, down_genes)

    if n_processes is None:
        n_processes = min(mp.cpu_count(), len(expr_matrix.columns))

    print(f"ğŸ”„ å¼€å§‹è®¡ç®—WTCSåˆ†æ•°...")
    print(f"   å¹¶è¡Œè¿›ç¨‹æ•°: {n_processes}")

    args_list = [(drug, expr_matrix[drug], up_overlap, down_overlap) for drug in expr_matrix.columns]

    if n_processes > 1:
        with mp.Pool(processes=n_processes) as pool:
            results = list(tqdm(pool.imap(analyze_single_drug, args_list), total=len(args_list), desc="å¤„ç†è¯ç‰©"))
    else:
        results = [analyze_single_drug(args) for args in tqdm(args_list, desc="å¤„ç†è¯ç‰©")]

    print("âœ… GSEAè®¡ç®—å®Œæˆï¼Œå¼€å§‹æ’åºå’ŒTauè®¡ç®—...")

    df = pd.DataFrame(results)

    # è¿‡æ»¤æ‰WTCSä¸ºNaNçš„è¡Œï¼ˆæ— æ•ˆè¯ç‰©ï¼‰
    initial_count = len(df)
    df = df.dropna(subset=['wtcs']).reset_index(drop=True)
    nan_count = initial_count - len(df)
    if nan_count > 0:
        print(f"âš ï¸ è¿‡æ»¤æ‰ {nan_count} ä¸ªæ— æ•ˆè¯ç‰©ï¼ˆæ— æœ‰æ•ˆWTCSåˆ†æ•°ï¼‰")

    if len(df) == 0:
        print("âŒ æ— æœ‰æ•ˆWTCSåˆ†æ•°ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
        return pd.DataFrame()

    # æŒ‰WTCSæ’åº + rank
    df = df.sort_values(by="wtcs", ascending=True).reset_index(drop=True)
    df["rank"] = df["wtcs"].rank(method="min", ascending=True).astype(int)

    # Tauè®¡ç®—
    n = len(df)
    if n > 1:
        percentile_ranks = rankdata(df["wtcs"], method="average") / n
        tau_scores = (percentile_ranks * 200) - 100
    else:
        tau_scores = [0.0]
    df["tau"] = tau_scores

    # æ•ˆæœåˆ†ç±»ï¼ˆåŸºäºTauï¼Œæ— æ˜¾è‘—æ€§ï¼‰
    def classify_effect(row):
        if row['tau'] < -90:
            return 'å¼ºé€†è½¬'
        elif row['tau'] < -50:
            return 'ä¸­ç­‰é€†è½¬'
        elif row['tau'] < 0:
            return 'å¼±é€†è½¬'
        else:
            return 'æ— æ•ˆæœ'

    df['effect_category'] = df.apply(classify_effect, axis=1)

    # é¶ç‚¹åŸºå› åˆ†æ•°
    print("ğŸ“Š æ·»åŠ é¶ç‚¹åŸºå› è¯¦ç»†åˆ†æ•°...")
    all_target_genes = list(up_overlap) + list(down_overlap)
    target_score_dict = {f"{gene}_score": [] for gene in all_target_genes}

    for _, row in df.iterrows():
        for gene in all_target_genes:
            target_score_dict[f"{gene}_score"].append(row["target_scores"].get(gene, np.nan))

    for gene in all_target_genes:
        df[f"{gene}_score"] = target_score_dict[f"{gene}_score"]

    # æŒ‰Tauæ’åºï¼ˆä»ä½åˆ°é«˜ï¼Œå³é€†è½¬æ½œåŠ›ä»å¼ºåˆ°å¼±ï¼‰
    result_df = df.sort_values(by="tau", ascending=True).reset_index(drop=True)
    result_df['final_rank'] = range(1, len(result_df) + 1)

    print("âœ… åˆ†æå®Œæˆ!")

    # æ‘˜è¦
    print(f"ğŸ“ˆ ç»“æœæ‘˜è¦:")
    print(f"   è¯ç‰©æ€»æ•°: {len(result_df)}")
    print(f"   å¼ºé€†è½¬è¯ç‰©: {(result_df['effect_category'] == 'å¼ºé€†è½¬').sum()} ä¸ª")
    print(f"   ä¸­ç­‰é€†è½¬è¯ç‰©: {(result_df['effect_category'] == 'ä¸­ç­‰é€†è½¬').sum()} ä¸ª")
    print(f"   å¼±é€†è½¬è¯ç‰©: {(result_df['effect_category'] == 'å¼±é€†è½¬').sum()} ä¸ª")
    print(f"   WTCSèŒƒå›´: {result_df['wtcs'].min():.4f} ~ {result_df['wtcs'].max():.4f}")
    print(f"   TauèŒƒå›´: {result_df['tau'].min():.1f} ~ {result_df['tau'].max():.1f}")

    return result_df


# === æ–°å¢: ESæ•£ç‚¹å›¾ç»˜åˆ¶å‡½æ•° ===
def plot_es_scatter(results_df, figsize=(12, 10)):
    """ç»˜åˆ¶ES_up vs ES_downæ•£ç‚¹å›¾"""
    # ç¡®ä¿DataFrameå·²æŒ‰WTCSå‡åºæ’åºï¼ˆä½WTCSä¸ºå¥½ï¼Œå³é€†è½¬æ•ˆæœå¼ºï¼‰
    sorted_df = results_df.sort_values(by='wtcs', ascending=True).reset_index(drop=True)

    fig, ax = plt.subplots(figsize=figsize)

    # æ ¹æ®WTCSå€¼è®¾ç½®é¢œè‰²
    scatter = ax.scatter(sorted_df['es_up'], sorted_df['es_down'],
                         c=sorted_df['wtcs'], cmap=LinearSegmentedColormap.from_list("custom", ['#FF9A9B', '#47B2FF']),
                         alpha=0.7, s=60, edgecolors='black', linewidth=0.5)

    # æ·»åŠ å¯¹è§’çº¿
    min_es = min(sorted_df['es_up'].min(), sorted_df['es_down'].min())
    max_es = max(sorted_df['es_up'].max(), sorted_df['es_down'].max())
    ax.plot([min_es, max_es], [min_es, max_es], color='black', linestyle='--', linewidth=2, alpha=1.0,
            label='ES_up = ES_down')

    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    ax.set_xlabel('ä¸Šè°ƒåŸºå› å¯Œé›†åˆ†æ•° (ES_up)')
    ax.set_ylabel('ä¸‹è°ƒåŸºå› å¯Œé›†åˆ†æ•° (ES_down)')
    ax.set_title('ä¸Šè°ƒ vs ä¸‹è°ƒåŸºå› å¯Œé›†åˆ†æ•°æ•£ç‚¹å›¾')

    # æ·»åŠ é¢œè‰²æ¡å¹¶ç¾åŒ–
    cbar = plt.colorbar(scatter, ax=ax, orientation='vertical', fraction=0.046, pad=0.04, aspect=30)
    cbar.set_label('WTCSåˆ†æ•°', rotation=270, labelpad=15)
    cbar.ax.tick_params(labelsize=10)
    cbar.outline.set_linewidth(1.5)

    ax.legend()
    plt.tight_layout()

    # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„ï¼Œ600 DPIï¼Œå¹¶æ·»åŠ bbox_inches='tight'ä»¥ä¼˜åŒ–è£å‰ª
    plt.savefig(r"C:\Users\19834\Desktop\æ–‡ç« \è¡¥å……ææ–™\ES_scatter_plot.png", dpi=600, bbox_inches='tight')
    plt.show()


# === æ–°å¢: Tau vs z-score å›¾ç»˜åˆ¶å‡½æ•° ===
def plot_tau_vs_zscore(figsize=(10, 6)):
    """ç»˜åˆ¶Tau vs z-scoreç†è®ºæ˜ å°„å›¾"""
    fig, ax = plt.subplots(figsize=figsize)

    # ç”ŸæˆTauå€¼
    tau = np.linspace(-100, 100, 1000)
    percentile = (tau + 100) / 200
    # é¿å…inf
    percentile = np.clip(percentile, 1e-5, 1 - 1e-5)
    z = norm.ppf(percentile)
    z = np.clip(z, -4, 4)

    # ä½¿ç”¨LineCollectionåˆ›å»ºæ¸å˜ç²—çº¿
    points = np.array([tau, z]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    norm_col = plt.Normalize(z.min(), z.max())
    cmap = LinearSegmentedColormap.from_list("custom", ['#D8AEC8', '#47B2FF'])
    lc = LineCollection(segments, cmap=cmap, norm=norm_col)
    lc.set_array(z)
    lc.set_linewidth(3)  # å¢åŠ çº¿å®½
    line = ax.add_collection(lc)

    # æ·»åŠ å…³é”®ç‚¹
    key_z = np.array([-3.0, -1.5, 0, 1.5, 3.0])
    key_percentile = norm.cdf(key_z)
    key_tau = (key_percentile * 200) - 100
    ax.scatter(key_tau, key_z, c=key_z, cmap=cmap, norm=norm_col, s=100, edgecolor='black', zorder=3)

    # æ·»åŠ é¢œè‰²æ¡å¹¶ç¾åŒ–
    cbar = plt.colorbar(line, ax=ax, orientation='vertical', fraction=0.046, pad=0.1, aspect=30)
    cbar.set_label('z-score', rotation=270, labelpad=15)
    cbar.set_ticks(key_z)
    cbar.ax.tick_params(labelsize=10)
    cbar.outline.set_linewidth(1.5)

    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    ax.set_xlabel('Tau Score (percentile)')
    ax.set_ylabel('z-score')
    ax.set_title('Drug Reversal Potential (Tau vs z-score)')

    # æ·»åŠ æ°´å¹³çº¿å’Œç½‘æ ¼
    ax.axhline(0, color='gray', linestyle='--', alpha=0.5)
    ax.grid(True, linestyle='--', alpha=0.3)

    # è°ƒæ•´è½´èŒƒå›´
    ax.set_xlim(-100, 100)
    ax.set_ylim(-4, 4)

    plt.tight_layout()

    # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„ï¼Œ600 DPIï¼Œå¹¶æ·»åŠ bbox_inches='tight'ä»¥ä¼˜åŒ–è£å‰ª
    plt.savefig(r"C:\Users\19834\Desktop\æ–‡ç« \è¡¥å……ææ–™\Tau_vs_zscore_plot.png", dpi=600, bbox_inches='tight')
    plt.show()



# === 7. ä¸»ç¨‹åºå…¥å£ ===
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„
    long_table_path = "D:/æœ±æµ©å®‡ITCMè¡¨è¾¾è°±æ¯”å¯¹æ•°æ®/results.csv"
    up_gene_path = "D:/æœ±æµ©å®‡ITCMè¡¨è¾¾è°±æ¯”å¯¹æ•°æ®/ä¸Šè°ƒ.csv"
    down_gene_path = "D:/æœ±æµ©å®‡ITCMè¡¨è¾¾è°±æ¯”å¯¹æ•°æ®/ä¸‹è°ƒ.csv"

    try:
        print("ğŸ“¥ åŠ è½½è¡¨è¾¾æ•°æ®...")
        expr_matrix = load_expression_matrix_from_long_table(long_table_path)

        if expr_matrix is None:
            raise ValueError("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")

        print("\nğŸ“¥ åŠ è½½åŸºå› é›†...")
        up_genes, down_genes = load_gene_set_from_symbol_files(up_gene_path, down_gene_path)

        if not up_genes or not down_genes:
            raise ValueError("åŸºå› é›†åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")

        print("\nğŸ”¬ å¼€å§‹WTCS + Tauåˆ†æï¼ˆæ— ç»Ÿè®¡æ£€éªŒï¼‰...")

        results_df = run_custom_wtcs(
            expr_matrix, up_genes, down_genes,
            n_processes=4  # å¯ä»¥è°ƒæ•´
        )

        # æ˜¾ç¤ºTopç»“æœ
        print(f"\nğŸ† Top 10 è¯ç‰©é€†è½¬æ’åï¼ˆTau ä»ä½åˆ°é«˜ï¼‰:")
        display_cols = ["drug_id", "wtcs", "tau", "effect_category"]
        print(results_df[display_cols].head(10).to_string(index=False))

        # ä¿å­˜
        output_path = "D:/æœ±æµ©å®‡ITCMè¡¨è¾¾è°±æ¯”å¯¹æ•°æ®/WTCS_TAU_results_no_stats.csv"
        results_df.to_csv(output_path, index=False)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_path}")

        # æ–°å¢: ç»˜åˆ¶ESæ•£ç‚¹å›¾
        print("\nğŸ“Š ç»˜åˆ¶ESæ•£ç‚¹å›¾...")
        plot_es_scatter(results_df)

        # æ–°å¢: ç»˜åˆ¶Tau vs z-scoreå›¾
        print("\nğŸ“Š ç»˜åˆ¶Tau vs z-scoreå›¾...")
        plot_tau_vs_zscore()

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback

        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())